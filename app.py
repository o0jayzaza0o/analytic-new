import streamlit as st
import pandas as pd
import plotly.express as px
import torch
import json_repair
from bs4 import BeautifulSoup
from unsloth import FastLanguageModel

# --- 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà Save ‡πÑ‡∏ß‡πâ ---
st.set_page_config(page_title="AI XML Analyst", layout="wide")

@st.cache_resource
def load_local_model():
    # ‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤ Save ‡πÑ‡∏ß‡πâ (mysaved_model)
    # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå mysaved_model ‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö app.py
    model_path = "mysaved_model" 
    max_seq_length = 2048
    dtype = None
    load_in_4bit = True
    
    try:
        model, tokenizer = FastLanguageModel.from_pretrained(
            model_name = model_path, # ‡∏ä‡∏µ‡πâ‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
            max_seq_length = max_seq_length,
            dtype = dtype,
            load_in_4bit = load_in_4bit,
        )
        FastLanguageModel.for_inference(model)
        return model, tokenizer
    except Exception as e:
        # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡πÉ‡∏´‡πâ‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å‡πÄ‡∏ô‡πá‡∏ï‡πÅ‡∏ó‡∏ô (Fallback)
        st.warning(f"‡∏´‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ({e}) ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å Unsloth ‡πÅ‡∏ó‡∏ô...")
        model, tokenizer = FastLanguageModel.from_pretrained(
            model_name = "unsloth/Llama-3.2-3B-Instruct",
            max_seq_length = max_seq_length,
            dtype = dtype,
            load_in_4bit = load_in_4bit,
        )
        FastLanguageModel.for_inference(model)
        return model, tokenizer

# --- 2. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏Å‡∏∞ XML Text ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå ---
def process_xml_text(xml_string, model, tokenizer):
    # ‡πÉ‡∏ä‡πâ BeautifulSoup ‡πÅ‡∏Å‡∏∞ XML string
    soup = BeautifulSoup(xml_string, 'xml')
    items = soup.find_all('item')
    
    if not items:
        # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏ì‡∏µ user ‡∏ß‡∏≤‡∏á‡∏°‡∏≤‡πÅ‡∏Ñ‡πà text ‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤ ‡πÑ‡∏°‡πà‡∏°‡∏µ tag item
        # ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏à‡∏≤‡∏Å root ‡∏´‡∏£‡∏∑‡∏≠‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô item ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
        if soup.find('title'):
            items = [soup]
        else:
            return []

    results = []
    
    # Progress Bar
    progress_bar = st.progress(0)
    status_text = st.empty()
    total = len(items)
    
    for i, item in enumerate(items):
        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Tag
        title = item.find('title').get_text() if item.find('title') else "No Title"
        description = item.find('description').get_text() if item.find('description') else ""
        link = item.find('link').get_text() if item.find('link') else ""
        
        # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ AI
        full_text = f"Title: {title}\nDescription: {description}"
        input_text = full_text[:1500]
        
        status_text.text(f"‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå: {title[:30]}...")
        
        # --- AI Inference Part ---
        prompt = f"""<|begin_of_text|><|start_header_id|>system<|end_header_id|>
        You are a News Analyst. Extract public figures and sentiment.
        Output JSON only: {{"persons": ["Name1", "Name2"], "sentiment": "Positive/Negative/Neutral"}}
        <|eot_id|><|start_header_id|>user<|end_header_id|>
        News: {input_text}
        <|eot_id|><|start_header_id|>assistant<|end_header_id|>"""
        
        inputs = tokenizer([prompt], return_tensors="pt").to("cuda")
        
        outputs = model.generate(
            **inputs, 
            max_new_tokens=128,
            use_cache=True,
            temperature=0.1
        )
        
        response = tokenizer.batch_decode(outputs)[0].split("assistant")[-1].strip()
        
        # Parse JSON
        try:
            data = json_repair.loads(response)
            sentiment = str(data.get('sentiment', 'Neutral'))
            persons = data.get('persons', [])
            if isinstance(persons, str): persons = [persons]
            persons = [str(p) for p in persons if isinstance(p, (str, int))]
        except:
            sentiment = "Error"
            persons = []
            
        results.append({
            "title": title,
            "sentiment_clean": sentiment,
            "persons_clean": persons,
            "link": link
        })
        
        progress_bar.progress((i + 1) / total)

    status_text.text("‚úÖ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")
    progress_bar.empty()
    return pd.DataFrame(results)

# --- 3. UI ‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠ ---
st.title("ü§ñ AI XML News Analyzer")
st.markdown("‡∏ß‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î XML (`<item>...</item>`) ‡∏•‡∏á‡πÉ‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•..."):
    try:
        model, tokenizer = load_local_model()
        st.success("Model Loaded Successfully! üöÄ")
    except Exception as e:
        st.error(f"Error loading model: {e}")
        st.stop()

# Input Text Area (‡∏£‡∏±‡∏ö XML)
xml_input = st.text_area("‡∏ß‡∏≤‡∏á XML Code ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà:", height=300, placeholder="<item>\n<title>Example News</title>\n...</item>")

if st.button("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå"):
    if not xml_input.strip():
        st.warning("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ß‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î XML ‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö")
    else:
        df = process_xml_text(xml_input, model, tokenizer)
        
        if not df.empty:
            st.session_state['data_xml'] = df
        else:
            st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô XML ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")

# --- 4. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• ---
if 'data_xml' in st.session_state:
    df = st.session_state['data_xml']
    st.divider()
    
    # Metrics
    c1, c2, c3 = st.columns(3)
    c1.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πà‡∏≤‡∏ß", len(df))
    c2.metric("‡∏Ç‡πà‡∏≤‡∏ß‡∏ö‡∏ß‡∏Å", len(df[df['sentiment_clean']=='Positive']))
    c3.metric("‡∏Ç‡πà‡∏≤‡∏ß‡∏•‡∏ö", len(df[df['sentiment_clean']=='Negative']))
    
    # Charts
    col_chart1, col_chart2 = st.columns(2)
    
    with col_chart1:
        st.subheader("Sentiment Analysis")
        fig_pie = px.pie(df, names='sentiment_clean', color='sentiment_clean',
                     color_discrete_map={'Positive':'#2ecc71', 'Negative':'#e74c3c', 'Neutral':'#f1c40f'})
        st.plotly_chart(fig_pie, use_container_width=True)
        
    with col_chart2:
        st.subheader("Top Figures")
        all_persons = []
        for p_list in df['persons_clean']:
            all_persons.extend(p_list)
            
        if all_persons:
            from collections import Counter
            counts = Counter(all_persons).most_common(10)
            df_p = pd.DataFrame(counts, columns=['Name', 'Count'])
            st.plotly_chart(px.bar(df_p, x='Count', y='Name', orientation='h'), use_container_width=True)
            
    # Table
    st.subheader("‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
    st.dataframe(df[['title', 'sentiment_clean', 'persons_clean']])
